{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import sys\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import torch.hub\n",
    "import os\n",
    "import model\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchsummary import summary\n",
    "from visualize.grad_cam import BackPropagation, GradCAM,GuidedBackPropagation\n",
    "from IPython import display\n",
    "import threading\n",
    "import time\n",
    "import vlc\n",
    "from random import seed,random, randint\n",
    "import pickle\n",
    "\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faceCascade = cv2.CascadeClassifier('visualize/haarcascade_frontalface_default.xml')\n",
    "shape = (48,48)\n",
    "classes = [\n",
    "    'Angry',\n",
    "    'Disgust',\n",
    "    'Fear',\n",
    "    'Happy',\n",
    "    'Sad',\n",
    "    'Surprised',\n",
    "    'Neutral'\n",
    "]\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiddenPrints:\n",
    "    def __enter__(self):\n",
    "        self._original_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = self._original_stdout\n",
    "\n",
    "def preprocess(image_path):\n",
    "    global faceCascade\n",
    "    global shape\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    image = cv2.imread(image_path)\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "        image,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=5,\n",
    "        minSize=(1, 1),\n",
    "        flags=cv2.CASCADE_SCALE_IMAGE\n",
    "    )\n",
    "    flag =0\n",
    "    if len(faces) == 0:\n",
    "        print('no face found')\n",
    "        face = cv2.resize(image, shape)\n",
    "    else:\n",
    "        (x, y, w, h) = faces[0]\n",
    "        face = image[y:y + h, x:x + w]\n",
    "        face = cv2.resize(face, shape)\n",
    "        flag=1\n",
    "\n",
    "    img = Image.fromarray(face).convert('L')\n",
    "    inputs = transform_test(img)\n",
    "    return inputs, face, flag\n",
    "\n",
    "def plotImage(path, mylabel):\n",
    "    global shape\n",
    "    img = cv2.imread(path)\n",
    "    dimensions = img.shape\n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "    cv2.putText(img, mylabel,(round(width/2)-40,height-20), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2, cv2.LINE_AA)\n",
    "    cv2.imwrite('temp-images/display.jpg',img) \n",
    "    img=mpimg.imread('temp-images/display.jpg')\n",
    "    plt.imshow(img)\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "\n",
    "def detect_emotion(images, model_name):\n",
    "    global classes\n",
    "    global device\n",
    "    flag=0\n",
    "    with HiddenPrints():\n",
    "        for i, image in enumerate(images):\n",
    "            target, raw_image,flag = preprocess(image['path'])\n",
    "            image['image'] = target\n",
    "            image['raw_image'] = raw_image\n",
    "\n",
    "        net = model.Model(num_classes=len(classes)).to(device)\n",
    "        checkpoint = torch.load(os.path.join('model', model_name), map_location=device)\n",
    "        net.load_state_dict(checkpoint['net'])\n",
    "        net.eval()\n",
    "        summary(net, (1, shape[0], shape[1]))\n",
    "\n",
    "        result_images = []\n",
    "    label = \"\"\n",
    "    if(flag):\n",
    "        for index, image in enumerate(images):\n",
    "            with HiddenPrints():\n",
    "                img = torch.stack([image['image']]).to(device)\n",
    "                bp = BackPropagation(model=net)\n",
    "                probs, ids = bp.forward(img)\n",
    "                actual_emotion = ids[:,0]\n",
    "            label = classes[actual_emotion.data]\n",
    "        plotImage(image['path'],label)\n",
    "    else:\n",
    "        plotImage(image['path'],label)\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed label\n",
    "with open(\"label\", \"wb\") as f:\n",
    "    pickle.dump(\"\", f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection():\n",
    "    global classes\n",
    "    video_capture = cv2.VideoCapture(0)\n",
    "    \n",
    "    while 1:\n",
    "        ret, frame = video_capture.read()\n",
    "        cv2.imwrite('temp-images/test.jpg',frame)\n",
    "        detection = detect_emotion(images=[{'path': 'temp-images/test.jpg'}],model_name='emotions.t7')\n",
    "        with open(\"label\", \"wb\") as f:\n",
    "            pickle.dump(detection, f)\n",
    "        \n",
    "            \n",
    "def music():\n",
    "    global classes\n",
    "    seed(round(random()*10))\n",
    "    counter = [0,0,0,0,0,0,0]\n",
    "    label=\"\"\n",
    "    status=\"Neutral\"\n",
    "    memstatus=\"\"\n",
    "    flag = 0\n",
    "    entries = os.listdir('music/Favs/')\n",
    "    value = randint(0, len(entries)-1)\n",
    "    p = vlc.MediaPlayer(\"music/Favs/\"+entries[value])\n",
    "    p.play()\n",
    "    while 1:\n",
    "        with open(\"label\", \"rb\") as f:\n",
    "            label = pickle.load(f)\n",
    "        time.sleep(1)\n",
    "        y=0\n",
    "        for x in classes:\n",
    "            if(x==label):\n",
    "                counter[y] = counter[y] + 1\n",
    "            y = y + 1 \n",
    "        y=0\n",
    "        for x in counter:\n",
    "            if(x == 10):\n",
    "                status = classes[y]\n",
    "                counter = [0,0,0,0,0,0,0]\n",
    "                flag = 1\n",
    "                break\n",
    "            y = y + 1\n",
    "        \n",
    "        if((status=='Angry' and flag and status!=memstatus) or (not(p.is_playing()) and status=='Angry' and flag)):\n",
    "            seed(round(random()*10))\n",
    "            memstatus = status\n",
    "            p.stop()\n",
    "            entries = os.listdir('music/Chill/')\n",
    "            value = randint(0, len(entries)-1)\n",
    "            p = vlc.MediaPlayer(\"music/Chill/\"+entries[value])\n",
    "            p.play()\n",
    "            \n",
    "        if(((status=='Neutral' or status=='Happy') and flag and status!=memstatus) or (not(p.is_playing()) and (status=='Neutral' or status=='Happy') and flag)):\n",
    "            seed(round(random()*10))\n",
    "            memstatus = status\n",
    "            p.stop()\n",
    "            entries = os.listdir('music/Favs/')\n",
    "            value = randint(0, len(entries)-1)\n",
    "            p = vlc.MediaPlayer(\"music/Favs/\"+entries[value])\n",
    "            p.play()\n",
    "            \n",
    "        if((status=='Sad' and flag and status!=memstatus) or (not(p.is_playing()) and status=='Sad' and flag)):\n",
    "            seed(round(random()*10))\n",
    "            memstatus = status\n",
    "            p.stop()\n",
    "            entries = os.listdir('music/Happy/')\n",
    "            value = randint(0, len(entries)-1)\n",
    "            p = vlc.MediaPlayer(\"music/Happy/\"+entries[value])\n",
    "            p.play()\n",
    "\n",
    "d = threading.Thread(target=detection, name='detection')\n",
    "m = threading.Thread(target=music, name='music')\n",
    "\n",
    "d.start()\n",
    "m.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
